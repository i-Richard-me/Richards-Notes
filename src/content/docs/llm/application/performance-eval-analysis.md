---
title: 利用大模型进行实体及属性抽取
description: 探索大语言模型在实体及属性抽取任务中的能力。
---

在之前的案例中，我们已经介绍了如何使用大语言模型从文本数据中进行情绪分类和主题分类任务。本篇将进一步探索，利用大模型的推理能力，进行进行实体及属性抽取，以从员工绩效评价文本中抽取关键能力标签为例。

## 案例说明

本案例基于上级对员工的绩效评价，目的是评估员工在以下几个维度的能力：业务与专业能力、协作与沟通能力、领导与管理能力、创新与适应能力、职业操守与自我管理能力。通过分析评价内容，模型能够推理出员工在这些能力维度的表现级别。

:::caution
能力评估维度是根据具体案例简化而来。实际应用中，建议采用成熟的胜任力测评工具。

如 Hay、Aon、德勤、北森等，均提供了相对科学且全面的胜任力评估维度和标准。
:::

:::note
测试的文本样本依旧使用 ChatGPT 辅助生成，如有雷同，纯属巧合。
:::

## 任务执行过程

### 1. 构建提示词

为了引导大模型正确理解并执行任务，我们构建了如下的提示词模板：

```python
evaluation_prompt = """
    作为人力资源专家，你的任务是分析绩效评价报告，从中评估员工在各个能力维度的表现。请按照以下步骤操作：

    1. 理解评价内容：深入阅读绩效评价文本，理解其中的描述和评价。
    2. 能力评估：根据绩效评价文本，评估员工在以下能力维度的表现级别：业务与专业能力，协作与沟通能力，领导与管理能力，创新与适应能力，职业操守与自我管理能力。根据评价内容，将能力表现分为“高”、“中”、“低”、或`未知`。
    3. 给出理由：为你的评估提供依据，即根据评价内容中的具体描述或表现，解释为何该员工在某个能力维度的评级为高、中、低或未知。
    4. 输出格式：将评估结果以及评估理由以JSON格式输出，确保格式的准确性和易读性。
        例如：业务与专业能力：["能力等级": "高", "评估理由": "员工在过去一年中，展现出了高超的业务技能，能够独立完成复杂的业务任务。"]
        
    请根据提供的绩效评价内容进行分析，避免任何主观臆断，确保评估结果客观、公正。

    注意事项：
    - 深入理解评价内容，确保评估准确性。
    - 使用明确的级别（“高”、“中”、“低”、"未知"）来描述员工的能力。
    - 提供评估理由，确保理由与评价内容直接相关。
    - 确保输出格式正确，便于阅读和理解。

    员工ID与绩效评价 >>>{query}<<<
    
    \n{format_instructions}
    """
```

接下来定义输出格式

```python
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field

class PerformanceEvaluation(BaseModel):
    """
    定义输出格式
    """
    ID: str = Field(description="员工ID")
    业务与专业能力: dict = Field(description="包含`能力等级`和`评估理由`")
    协作与沟通能力: dict = Field(description="包含`能力等级`和`评估理由`。")
    领导与管理能力: dict = Field(description="包含`能力等级`和`评估理由`。")
    创新与适应能力: dict = Field(description="包含`能力等级`和`评估理由`。")
    职业操守与自我管理能力: dict = Field(description="包含`能力等级`和`评估理由`。")

parser = JsonOutputParser(pydantic_object=PerformanceEvaluation)
```

### 2. 构建任务模型

使用 Langchain 构建任务，通过下面的代码定义如何获取评价数据并执行任务：

```python
prompt = PromptTemplate(
    template=evaluation_prompt,
    input_variables=["query"],
)

chain = prompt | model | paser

# 定义函数获取第 i 行回复数据
def get_query(i):
    query = {
        "ID": data.loc[i, "emp"],
        "text": data.loc[i, "上级评价"]
    }
    return query
```

### 3. 效果测试

测试文本如下，用以评估模型的输出效果：

```python
text = get_query(0)
text
```

```text
{'ID': 'ID0001',
 'text': '1、成果显著、具备良好的价值导向、持续自我提升的动力。
 2、希望能持续成为团队的典范，激励并引领团队成员共同进步。
 3、在处理商业运营的复杂挑战和竞争策略探索方面表现出色。'}
```

大模型输出的评估结果如下：

```python
chain_result = chain.invoke({"query": text})
chain_result
```

```text
{'ID': 'ID0017',
 '业务与专业能力': {'能力等级': '高',
  '评估理由': '评价内容提到员工在处理商业运营的复杂挑战和竞争策略探索方面表现出色，说明其业务专业能力很强，能够独立完成复杂的任务。'},
 '协作与沟通能力': {'能力等级': '高',
  '评估理由': '员工希望持续成为团队的典范，激励并引领团队成员，这表明他们在协作与沟通方面具有较高的能力，能够有效地与团队协作并影响他人。'},
 '领导与管理能力': {'能力等级': '未知',
  '评估理由': '虽然提到员工有激励团队的意愿，但评价内容中没有直接提及领导和管理的具体表现，因此这部分能力等级暂定为未知。'},
 '创新与适应能力': {'能力等级': '中',
  '评估理由': '评价中提到员工有自我提升的驱动力，但没有直接提及创新的具体例子，所以创新能力评级为中等。'},
 '职业操守与自我管理能力': {'能力等级': '高',
  '评估理由': '评价提到员工有良好的价值导向，这表明他们在职业操守方面表现出色，自我管理能力强。'}}
```

可以看到，大模型基本给出了我们可以接受的回答。

:::tip
当然，为了进一步提升评估效果，依然有很多优化策略，例如每个任务只单独评估一个能力维度，并为每个维度提供判断标准和示例案例，都是提高评估的准确性的有效手段。
:::