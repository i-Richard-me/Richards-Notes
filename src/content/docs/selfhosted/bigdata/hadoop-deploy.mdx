---
title: "Hadoop 集群部署"
description: ""
---

:::caution
这是一篇早年学习大数据知识时的笔记，记录了 Hadoop 集群部署的详细过程。由于时间较早，部分内容可能已经过时，仅供参考。
:::

import { Steps } from '@astrojs/starlight/components';

学习中以三台虚拟机为例，主机名分别为hadoop01、hadoop02、hadoop03，系统为RockyLinux 8。

## 环境准备

### 虚拟机创建

:::tip
若多台虚拟机使用克隆的方式创建，需要按如下步骤分别修改主机名和静态ip地址，避免冲突。若各个虚拟机采用独立安装，则可在安装时直接配置好主机名和静态ip地址。
:::


<Steps>
1. 修改主机名

    ```bash
    hostnamectl set-hostname hadoop01 # hadoop02、hadoop03
    ```

2. 修改静态 ip 地址

    ```bash
    vim /etc/sysconfig/network-scripts/ifcfg-ens33
    ```

    ```bash
    ...
    BOOTPROTO=static
    ...
    IPADDR="192.168.1.2"    # 每台虚拟机的 ip 地址不同
    NETMASK="255.255.255.0" # 子网掩码，一般不用修改
    GATEWAY="192.168.1.1"   # 网关地址
    DNS1="192.168.1.1"      # DNS地址，可与网关地址相同
    ```
</Steps>

### 用户配置

:::caution
用户配置可以通过 xshell `发送键入到所有会话窗口` 的功能，同时在三台主机上执行，可以简化 ssh 免密登录的重复操作。否则需要在每台主机上分别执行。
:::

<Steps>
1. 配置 hosts 主机名映射

    ```bash
    vim /etc/hosts
    ```

    ```
    192.168.100.61 hadoop01
    192.168.100.62 hadoop02
    192.168.100.63 hadoop03
    ```

2. 配置 root 用户 ssh 免密登录

    1. 生成密钥对

        ```bash
        ssh-keygen -t rsa
        ```

    2. 将公钥分发到各个节点

        ```bash
        ssh-copy-id hadoop01
        ssh-copy-id hadoop02
        ssh-copy-id hadoop03
        ```

3. 创建 hadoop 用户

    ```bash
    useradd hadoop
    passwd hadoop
    ```

4. 配置 hadoop 用户 sudo 权限

    ```bash
    vim /etc/sudoers
    ```

    :::caution
    以下配置需要在 %wheel ALL=(ALL) ALL 之后添加，否则无效。因为所有用户都在 %wheel 组中，若在 %wheel 之前添加，则会被之后的 %wheel 这一行配置覆盖。
    :::

    ```bash
    hadoop ALL=(ALL) NOPASSWD: ALL
    ```

5. 配置 hadoop 用户 ssh 免密登录

    1. 切换到 hadoop 用户
        ```bash
        su - hadoop
        ```

    2. 生成密钥对
        ```bash
        ssh-keygen -t rsa
        ```

    3. 将公钥分发到各个节点
        ```bash
        ssh-copy-id hadoop01
        ssh-copy-id hadoop02
        ssh-copy-id hadoop03
        ```
</Steps>

### 系统配置

<Steps>
1. 关闭防火墙

    ```bash
    systemctl stop firewalld
    systemctl disable firewalld.service
    ```

2. 关闭 SELinux

    ```bash
    vim /etc/selinux/config
    ```

    ```bash
    ...
    SELINUX=disabled
    ...
    ```

3. 永久关闭 swap

    ```bash
    swapoff -a
    vim /etc/fstab
    ```

    ```bash
    # 注释掉 swap 行
    ...
    #/dev/mapper/cl-swap swap                    swap    defaults        0 0
    ...
    ```

4. 配置时间同步

    Rocky Linux 9 默认使用 chrony 作为时间同步服务。而 CentOS 7/8 默认使用 ntpd 作为时间同步服务。

    ```bash
    vim /etc/chrony.conf
    ```

    ```bash
    ...
    server ntp.aliyun.com iburst
    ...
    ```

    ```bash
    systemctl restart chronyd && systemctl status chronyd
    systemctl start chronyd
    systemctl enable chronyd
    ```
</Steps>

### 安装 JDK

<Steps>
1. 创建目录

    1. 创建目录
        ```bash
        mkdir -p /opt/bigdata # 用于存放软件
        mkdir -p /opt/software # 用于存放安装包
        ```

    2. 授权给 hadoop 用户
        ```bash
        chown -R hadoop:hadoop /opt/bigdata
        chown -R hadoop:hadoop /opt/software
        ```

2. 上传 `jdk-8u212-linux-x64.tar.gz` 到 `/bigdata/software` 目录

3. 解压
    ```bash
    tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/bigdata
    ```

4. 创建软链接
    ```bash
    ln -s /opt/bigdata/jdk1.8.0_212 /opt/bigdata/jdk
    ```

5. 配置环境变量
    ```bash
    vim /etc/profile.d/bigdata.sh
    ```

    ```bash
    export JAVA_HOME=/opt/bigdata/jdk
    export PATH=$PATH:$JAVA_HOME/bin
    ```

6. 使环境变量生效

   :::tip
   通过 `source` 命令使环境变量生效，不需要重启系统，但是只对当前 shell 会话生效，若同时打开多个 shell 会话，则需要在每个 shell 会话中执行此命令，或者重启系统。
   :::

    ```bash
    source /etc/profile.d/bigdata.sh
    ```

7. 配置 JAVA 执行程序的软链接（可选）
    ```bash
    ln -s /opt/bigdata/jdk/bin/java /usr/bin/java
    ln -s /opt/bigdata/jdk/bin/jps /usr/bin/jps
    ```
</Steps>

## HDFS 部署

### 节点规划

| 主机名   | 角色                        |
| -------- | --------------------------- |
| hadoop01 | NameNode、DataNode          |
| hadoop02 | DataNode                    |
| hadoop03 | DataNode、SecondaryNameNode |

### 准备程序文件

<Steps>
1. 下载 Hadoop 程序包

    :::tip
    若下载速度过慢，可更换使用国内镜像如 [清华大学开源软件镜像站](https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/) 下载
    :::

    ```bash
    cd /opt/software
    wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.4/hadoop-3.3.4.tar.gz
       ```

2. 解压

    ```bash
    tar -zxvf /opt/software/hadoop-3.3.4.tar.gz -C /opt/bigdata
       ```

3. 创建软链接

    ```bash
    ln -s /opt/bigdata/hadoop-3.3.4 /opt/bigdata/hadoop
       ```
</Steps>

### 配置步骤

<Steps>

1. 配置环境变量

    ```bash
    vim /etc/profile.d/bigdata.sh
    ```

    ```bash
    export HADOOP_HOME=/opt/bigdata/hadoop
    export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
    ```

    ```bash
    source /etc/profile.d/bigdata.sh
    ```

2. 配置 workers

    ```bash
    vim /opt/bigdata/hadoop/etc/hadoop/workers
    ```

    ```bash
    hadoop01
    hadoop02
    hadoop03
    ```

3. 配置 core-site.xml

    ```bash
    vim /opt/bigdata/hadoop/etc/hadoop/core-site.xml
    ```

    ```xml
        <property>
            <name>fs.defaultFS</name>
            <value>hdfs://hadoop01:8020</value>
        </property>
    ```

4. 配置 hdfs-site.xml

    ```bash
    vim /opt/bigdata/hadoop/etc/hadoop/hdfs-site.xml
    ```

    :::caution
    针对副本数量 `dfs.replication`，由于我们在家中部署时，多数情况下三台虚拟机均在同一台物理机上和硬盘上，设置多个副本没有实际意义，反而浪费磁盘空间，所以设置为 1。生产环境中，需要修改为 3。
    :::

    ```xml
        <!-- namenode地址 -->
        <property>
            <name>dfs.namenode.http-address</name>
            <value>hadoop01:9870</value>
        </property>
        <!-- secondarynamenode地址 -->
        <property>
            <name>dfs.namenode.secondary.http-address</name>
            <value>hadoop03:9868</value>
        </property>
        <!-- 副本数量 -->
        <property>
            <name>dfs.replication</name>
            <value>1</value>
        </property>
        <!-- 指定哪些节点作为 NameNode -->
        <property>
            <name>dfs.namenode.hosts</name>
            <value>hadoop01, hadoop02, hadoop03</value>
        </property>
    ```

5. 分发到其他节点

    :::warning
    文件夹 `/opt/bigdata/hadoop-3.3.4` 只可在集群初次启动之前分发，若已启动过，不可再分发，因为每个节点生成的数据不同，分发后会导致集群损坏。
    :::

    ```bash
    xsync /opt/bigdata/hadoop-3.3.4
    ```
</Steps>

### HDFS 集群启动

<Steps>
1. 格式化 NameNode

    ```bash
    su - hadoop
       ```

    ```bash
    hdfs namenode -format
       ```

2. 启动 HDFS

    ```bash
    start-dfs.sh
       ```

3. 查看进程

    ```bash
    jps
       ```

4. 停止 HDFS

    ```bash
    stop-dfs.sh
       ```
</Steps>

### 访问 HDFS

1. 访问 NameNode

    ```bash
    http://hadoop01:9870
       ```

2. 访问 DataNode

    ```bash
    http://hadoop02:9864
    http://hadoop03:9864
       ```

3. 访问 SecondaryNameNode

    ```bash
    http://hadoop03:9868
       ```

## YARN 部署

### 节点规划

| 主机名   | 角色                         |
| -------- | ---------------------------- |
| hadoop01 | Nodemanager                  |
| hadoop02 | ResourceManager、Nodemanager |
| hadoop03 | Nodemanager                  |

### 配置步骤

<Steps>
1. 配置 yarn-site.xml

    ```bash
    vim /opt/bigdata/hadoop/etc/hadoop/yarn-site.xml
    ```

    ```xml
        <!-- 为 MapReduce 开启 shuffle 服务 -->
        <property>
            <name>yarn.nodemanager.aux-services</name>
            <value>mapreduce_shuffle</value>
        </property>
        <!-- 设置ResourceManager的节点 -->
        <property>
            <name>yarn.resourcemanager.hostname</name>
            <value>hadoop02</value>
        </property>
        <!-- 设置环境变量的继承 -->
        <property>
            <name>yarn.nodemanager.env-whitelist</name>
            <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
        </property>
        <!-- 关闭yarn对虚拟内存的检查 -->
        <property>
            <name>yarn.nodemanager.vmem-check-enabled</name>
            <value>false</value>
        </property>
        <!-- 开启日志聚合 -->
        <property>
            <name>yarn.log-aggregation-enable</name>
            <value>true</value>
        </property>
        <!-- 设置 历史服务器 日志聚合 URL -->
        <property>
            <name>yarn.log.server.url</name>
            <value>http://hadoop01:19888/jobhistory/logs</value>
        </property>
        <!-- 设置日志保留时间为 30 天 -->
        <property>
            <name>yarn.log-aggregation.retain-seconds</name>
            <value>2592000</value>
        </property>


        <!-- 选择公平调度器 -->
        <property>
            <name>yarn.resourcemanager.scheduler.class</name>
            <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>
        </property>
    ```

2. 配置 mapred-site.xml

    ```bash
    vim /opt/bigdata/hadoop/etc/hadoop/mapred-site.xml
    ```

    ```xml
        <!-- 设置MapReduce框架运行在YARN上 -->
        <property>
            <name>mapreduce.framework.name</name>
            <value>yarn</value>
        </property>
        <!-- 设置MapReduce的JobHistoryServer的地址 -->
        <property>
            <name>mapreduce.jobhistory.address</name>
            <value>hadoop01:10020</value>
        </property>
        <!-- 设置MapReduce的JobHistoryServer的web地址 -->
        <property>
            <name>mapreduce.jobhistory.webapp.address</name>
            <value>hadoop01:19888</value>
        </property>
    ```

3. 分发配置文件

    :::warning
    注意只分发 /hadoop-3.3.4/etc/hadoop 配置文件夹，切勿同步整个 /opt/bigdata/hadoop-3.3.4 文件夹。
    :::

    ```bash
    xsync /opt/bigdata/hadoop-3.3.4/etc/hadoop
    ```
</Steps>

### 启动 YARN 集群启动

<Steps>
1. 启动 YARN

    ```bash
    start-yarn.sh
       ```

2. 启动历史服务器

    ```bash
    hadoop --daemon start historyserver
       ```

3. 停止 YARN

    ```bash
    hadoop --daemon stop historyserver
    stop-yarn.sh
       ```
</Steps>

### 访问 YARN 集群

1. 访问 ResourceManager

    ```bash
    http://hadoop02:8088
       ```

2. 访问历史服务器

    ```bash
    http://hadoop01:19888
       ```